{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Exploration, Cleaning, and Subset Construction**\n",
        "This notebook performs the initial end-to-end preparation of the Spotify multimodal dataset used throughout the Spectral Neighbor Plus recommender prototype. It focuses on inspecting the raw data, identifying usable fields, and producing a clean, well-structured subset suitable for downstream lyricâ€“audio similarity modeling."
      ],
      "metadata": {
        "id": "I06-g_CUHIsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block creates the authentication file required for accessing Kaggle datasets programmatically. It builds a kaggle.json file containing your API token, places it in the default Kaggle configuration directory (/root/.kaggle), and sets secure file permissions so the Kaggle client can read it safely. After writing the credentials, the script confirms successful setup, enabling authenticated dataset downloads in later steps."
      ],
      "metadata": {
        "id": "sH4UL9m3Htxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "# Replace YOUR_TOKEN_HERE with your actual KGAT token\n",
        "token = \"KGAT_e7686f15ad94b4378eb0b4fe722d0eb7\"\n",
        "\n",
        "kaggle_data = {\n",
        "    \"username\": \"\",\n",
        "    \"key\": token\n",
        "}\n",
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_data, f)\n",
        "\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
        "\n",
        "print(\"kaggle.json created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnKWrLeoJpzo",
        "outputId": "2b0df4a8-5db4-4da6-bbe0-12c03950f625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell installs the Kaggle client and configures the environment variables needed for authenticated downloads. Once the credentials are set, it fetches the 900k Spotify dataset directly into a raw data directory and unzips the archive for inspection. After extraction, the script scans the folder for any CSV, JSON, or Parquet files present in the dataset, returning a list so you can quickly identify which files are available for loading and exploration."
      ],
      "metadata": {
        "id": "ESL4vqjcH2Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "import os, zipfile, pandas as pd\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"YOUR_USERNAME\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"KGAT_e7686f15ad94b4378eb0b4fe722d0eb7\"\n",
        "\n",
        "!kaggle datasets download -d devdope/900k-spotify -p data/raw/spotify_900k\n",
        "\n",
        "zip_path = \"/content/data/raw/spotify_900k/900k-spotify.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(\"data/raw/spotify_900k\")\n",
        "\n",
        "# Load the biggest CSV/JSON/Parquet file and peek\n",
        "files = [f for f in os.listdir(\"data/raw/spotify_900k\") if f.endswith((\".csv\", \".json\", \".parquet\"))]\n",
        "files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCvutRqBJ3mf",
        "outputId": "bb045bc5-dd08-4ee4-d446-15813e346b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Dataset URL: https://www.kaggle.com/datasets/devdope/900k-spotify\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "900k-spotify.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['900k Definitive Spotify Dataset.json',\n",
              " 'spotify_dataset.csv',\n",
              " 'final_milliondataset_BERT_500K_revised.json']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is loaded into a pandas DataFrame, and a quick preview is shown to verify the contents. The column list is printed as well, giving a compact overview of all available features."
      ],
      "metadata": {
        "id": "cLZRrkF3IFcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"//content/data/raw/spotify_900k/spotify_dataset.csv\")\n",
        "df.head()\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd_X3tJ2MrWi",
        "outputId": "32cee0e5-74f2-4583-9f32-7dece86aa428"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album',\n",
              "       'Release Date', 'Key', 'Tempo', 'Loudness (db)', 'Time signature',\n",
              "       'Explicit', 'Popularity', 'Energy', 'Danceability', 'Positiveness',\n",
              "       'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness',\n",
              "       'Good for Party', 'Good for Work/Study',\n",
              "       'Good for Relaxation/Meditation', 'Good for Exercise',\n",
              "       'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving',\n",
              "       'Good for Social Gatherings', 'Good for Morning Routine',\n",
              "       'Similar Artist 1', 'Similar Song 1', 'Similarity Score 1',\n",
              "       'Similar Artist 2', 'Similar Song 2', 'Similarity Score 2',\n",
              "       'Similar Artist 3', 'Similar Song 3', 'Similarity Score 3'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A filtered subset of the dataset is created by keeping only rows with valid lyrics and key audio features, and removing tracks with extremely short text. From the cleaned data, a 20k-track sample containing only the relevant columns is drawn for more manageable downstream processing. The resulting curated sample is then saved to the processed data directory."
      ],
      "metadata": {
        "id": "R7SfgHPgIDqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cols_needed = [\n",
        "    \"Artist(s)\", \"song\", \"text\",\n",
        "    \"Genre\", \"Album\", \"emotion\",\n",
        "    \"Energy\", \"Danceability\", \"Positiveness\",\n",
        "    \"Acousticness\", \"Instrumentalness\", \"Speechiness\",\n",
        "    \"Liveness\", \"Tempo\", \"Loudness (db)\",\n",
        "    \"Popularity\"\n",
        "]\n",
        "\n",
        "df_small = df.dropna(subset=[\"text\", \"Energy\", \"Danceability\", \"Positiveness\"]).copy()\n",
        "df_small = df_small[df_small[\"text\"].str.len() > 50]  # filter out super-short lyrics\n",
        "\n",
        "df_sample = df_small[cols_needed].sample(n=20000, random_state=42)\n",
        "\n",
        "os.makedirs(\"data/processed\", exist_ok=True)\n",
        "df_sample.to_csv(\"data/processed/spotify_900k_sample.csv\", index=False)"
      ],
      "metadata": {
        "id": "WlZ93w86PBO2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell defines the column groups used throughout the projects audio features, lyrics, and contextual metadata. It also provides a small helper function that loads the processed Spotify sample and returns both the DataFrame and the predefined column lists. This keeps later notebooks cleaner by centralizing column references in one place."
      ],
      "metadata": {
        "id": "h372mSULIUIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "AUDIO_FEATURE_COLS = [\n",
        "    \"energy\", \"danceability\", \"valence\",\n",
        "    \"acousticness\", \"instrumentalness\",\n",
        "    \"speechiness\", \"liveness\", \"tempo\", \"loudness\", \"popularity\"\n",
        "]\n",
        "\n",
        "LYRICS_COL = \"text\"\n",
        "CONTEXT_COLS = [\"artist\", \"title\", \"genre\", \"album\", \"emotion\"]\n",
        "\n",
        "def load_spotify_sample(path: str = \"data/processed/spotify_900k_sample.csv\"):\n",
        "    path = Path(path)\n",
        "    df = pd.read_csv(path)\n",
        "    return df, AUDIO_FEATURE_COLS, LYRICS_COL, CONTEXT_COLS"
      ],
      "metadata": {
        "id": "k3ctALXFP49P"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}